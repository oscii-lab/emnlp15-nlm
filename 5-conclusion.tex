\section{Conclusion}
\label{sec:conclusion}

Recurrent neural network-based deep learning approaches
to machine translation have performed well on a limited vocabulary
size. In this paper, we developed a novel approach for compressing
the source and target text based on Huffman coding schemes. By doing
so, we eliminate the use of the \emph{unknown word} symbol,
and we allow the system to naturally learn translations corresponding
to the rare words in the text. We evaluated performance on the English-French
parallel corpora from ACL WMT '14 and compared it with that of the architecture
proposed by \newcite{journals/corr/BahdanauCB14}, using the BLEU score metric.
We found that our system improves TODO