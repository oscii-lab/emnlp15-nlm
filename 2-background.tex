\section{Background}
\label{sec:background}

\subsection{Neural Machine Translation}
One recent approach to neural machine translation predicts both a translation
and its alignment to the source sentence \newcite{journals/corr/ChoMGBSB14}.

The architecture consists of an encoder and a decoder. The encoder receives a
source text sentence $\mathbf{x}$ and encodes each prefix using a recurrent
network that combines embeddings $x_j$ for each word position $j$ in
$\mathbf{x}$:
\begin{equation}
\overrightarrow{h}_{j} = f(x_{j}, \overrightarrow{h}_{j-1})
\end{equation},
where $f$ is a non-linear function. Reverse encodings $\overleftarrow{h}_j$
are computed similarly to represent suffixes of the sentence. These vector
representations are stacked to form $h_j$, a representation of the sentence
focused on position $j$.

The decoder predicts each target symbol $\mathbf{y_i}$ sequentially according
to the distribution
\begin{equation}
P(y_{i} | y_{i-1}, ..., y_{1}, \mathbf{x}) = g(y_{i-1}, s_i, c_i)
\label{eqn:normalize}
\end{equation},
where $s_i$ is a hidden decoder state, $c_i$ is a \emph{summary} of the entire
input sequence, and $g$ is another non-linear function. Encoder and decoder
parameters are jointly optimized to maximize the log likelihood of a training
corpus.

Depending on the approach to neural translation, $c$ can take multiple forms.
\newcite{journals/corr/ChoMGBSB14} proposes integrating an attention mechanism
in the decoder, which is trained to determine on which portions of the source
sentence to focus. The decoder computes $c_{i}$, the summarizing context
vector, as a convex combination of the $h_{j}$. The coefficients of this
combination are proportional to an alignment model prediction $\exp a(h_j,
s_i)$, where $a$ is a non-linear function.

The speed of prediction scales with the output vocabulary size, due to the
denominator of Equation~\ref{eqn:normalize} \cite{journals/corr/JeanCMB14}. The
input vocabulary size is also a challenge for storage and learning. As aa
result, neural machine translation systems only consider the top 30K to 100K
most frequent words in a training corpus, replacing the other words with an
\emph{unknown word} symbol.

\subsection{Related Work}
There has been much recent work in improving translation quality with a large vocabulary size.
\newcite{journals/corr/LuongSLVZ14} describe an approach
that, similar to ours, treats the translation system as a black box. They eliminate unknown symbols by training the
system to recognize from where in the source text each unknown word in the target text came, so that in a postprocessing
 phase, the unknown word can be replaced by a dictionary lookup of the corresponding source text word. In contrast,
our method does not rely on having a complete dictionary, and instead transforms the data to allow the system itself to
learn translations for even the rare words.\\

Some approaches have altered the model itself to circumvent the expensive normalization computation, rather than
applying preprocessing and postprocessing on the text. \newcite{journals/corr/JeanCMB14}
develop an importance sampling strategy for estimating the exponent term in equation (4), thus leading to
an approximation of the softmax computation. \newcite{NIPS2013_5165}
present a technique for approximation of target word probability using noise-contrastive estimation. Our method can
be applied in conjunction with these techniques.\\

Sequential or hierarchical encodings of large vocabularies have played an
improtant role in recurrent neural network language models, primarily to
address the inference time issue of large vocabularies. \newcite{5947611}
describe an architecture in which output word types are grouped into classes by
frequency, and the network first predicts a class and then a word in that
class. \newcite{journals/corr/abs-1301-3781} describe an encoding of the output
vocabulary as a binary tree. To our knowledge, hierarchical encodings have not
been applied to input vocabulary encoding for translation.\\

Other methods have been also developed to work around large-vocabulary issues in
language modeling. \newcite{Morin05hierarchicalprobabilistic}, \newcite{NIPS2008_3583},
and \newcite{strategies} develop hierarchical versions of
the softmax computation; \newcite{Huang:2012:IWR:2390524.2390645}
and \newcite{Collobert:2008:UAN:1390156.1390177} remove the need for normalization,
thus avoiding computation of the summation term over the entire vocabulary.

\subsection{Huffman Codes}

An encoding can be used to represent a sequence of tokens from a large
vocabulary $\mathcal{V}$ using a small vocabulary $\mathcal{W}$.  In the case
of translation, let $\mathcal{V}$ be the original corpus vocabulary, which can
number in the millions of word types in a typical corpus. Let $\mathcal{W}$ be
the limited vocabulary size of a neural translation model, which is typically
set to a much smaller number such as 30,000. Let $V=|\mathcal{V}|$ and
$W=|\mathcal{W}|$.

A deterministically invertible, variable-length encoding maps each
$v\in\mathcal{V}$ to a sequence $w \in \mathcal{W}+$ such that no other
$v'\in\mathcal{V}$ is mapped to a prefix of $w$. Encoding simply replaces each
element of $V$ with its encoding, and decoding is unambiguous because of this
prefix restriction. An encoding can be represented as a tree in which each leaf
corresponds to an element of $V$, each node contains a symbol from
$\mathcal{W}$, and the encoding of any leaf is its path from the root.

A Huffman code is an optimal encoding that uses as few symbols from
$\mathcal{W}$ as possible to encode an original sequence of symbols from
$\mathcal{V}$. Although binary codes are typical, $\mathcal{W}$ can have any
size. An optimal encoding can be found using a greedy algorithm
\cite{huffman}.
